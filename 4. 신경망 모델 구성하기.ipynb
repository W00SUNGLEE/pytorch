{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/9mp9ylPuhO7ggYG3K3Rw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#신경망 모델 구성하기\n","신경망은 데이터에 대한 연산을 수행하는 계층(layer)/모듈(module)로 구성되어 있습니다. torch.nn 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소를 제공합니다. PyTorch의 모든 모듈은 nn.Module 의 하위 클래스(subclass) 입니다. 신경망은 다른 모듈(계층; layer)로 구성된 모듈입니다. 이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있습니다.\n","\n","이어지는 장에서는 FashionMNIST 데이터셋의 이미지들을 분류하는 신경망을 구성해보겠습니다."],"metadata":{"id":"bSrRRRLmnFFl"}},{"cell_type":"code","source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"],"metadata":{"id":"-23i9cAhnEtG","executionInfo":{"status":"ok","timestamp":1677211881509,"user_tz":-540,"elapsed":4764,"user":{"displayName":"이우성","userId":"00926902840550518962"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["##학습을 위한 장치 얻기\n","가능한 경우 GPU와 같은 하드웨어 가속기에서 모델을 학습하려고 합니다. torch.cuda 를 사용할 수 있는지 확인하고 그렇지 않으면 CPU를 계속 사용합니다."],"metadata":{"id":"5iYO5hL5np0O"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVsMG03UnAAf","executionInfo":{"status":"ok","timestamp":1677211900469,"user_tz":-540,"elapsed":269,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"8682dfdb-4171-4dfb-81e6-797e0dd186e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","source":["##클래스 정의하기\n","신경망 모델을 nn.Module 의 하위클래스로 정의하고, __init__ 에서 신경망 계층들을 초기화합니다. nn.Module 을 상속받은 모든 클래스는 forward 메소드에 입력 데이터에 대한 연산들을 구현합니다."],"metadata":{"id":"E6pUoxKpnw_f"}},{"cell_type":"code","source":["class NeuralNetwork(nn.Module):\n","  def __init__(self):\n","    super(NeuralNetwork, self).__init__()\n","    self.flatten = nn.Flatten()\n","    self.linear_relu_stack = nn.Sequential(\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 10),\n","    )\n","\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.linear_relu_stack(x)\n","    return logits"],"metadata":{"id":"NEydu3SRnpYK","executionInfo":{"status":"ok","timestamp":1677213256651,"user_tz":-540,"elapsed":261,"user":{"displayName":"이우성","userId":"00926902840550518962"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["NeuralNetwork 의 인스턴스(instance)를 생성하고 이를 device 로 이동한 뒤, 구조(structure)를 출력합니다."],"metadata":{"id":"Xxk_4EtlsxDq"}},{"cell_type":"code","source":["model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jd70HGrrsxwf","executionInfo":{"status":"ok","timestamp":1677213257971,"user_tz":-540,"elapsed":3,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"bbed56da-77b3-4824-d4d8-6b491717ddb7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["모델을 사용하기 위해 입력 데이터를 전달합니다. 이는 일부 백그라운드 연산들 과 함께 모델의 forward 를 실행합니다. model.forward() 를 직접 호출하지 마세요!\n","\n","모델에 입력을 전달하여 호출하면 2차원 텐서를 반환합니다. 2차원 텐서의 dim=0은 각 분류(class)에 대한 원시(raw) 예측값 10개가, dim=1에는 각 출력의 개별 값들이 해당합니다. 원시 예측값을 nn.Softmax 모듈의 인스턴스에 통과시켜 예측 확률을 얻습니다."],"metadata":{"id":"mj4UqmQMtOFJ"}},{"cell_type":"code","source":["X = torch.rand(1, 28, 28, device=device)\n","logits = model(X)\n","pred_probab = nn.Softmax(dim=1)(logits)\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class: {y_pred}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljZ3jK_Nsza_","executionInfo":{"status":"ok","timestamp":1677213389252,"user_tz":-540,"elapsed":308,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"157d9fc7-00f9-41de-83b7-dd12f941cb5d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: tensor([7])\n"]}]},{"cell_type":"markdown","source":["##모델 계층(Layer)\n","FashionMNIST 모델의 계층들을 살펴보겠습니다. 이를 설명하기 위해, 28x28 크기의 이미지 3개로 구성된 미니배치를 가져와, 신경망을 통과할 때 어떤 일이 발생하는지 알아보겠습니다."],"metadata":{"id":"oLZJYOWUuzFJ"}},{"cell_type":"code","source":["input_image = torch.rand(3,28,28)\n","print(input_image.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKenp1VjtDqc","executionInfo":{"status":"ok","timestamp":1677213789482,"user_tz":-540,"elapsed":10,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"1780f1e5-41ad-4236-da6c-942c51f6b04c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 28, 28])\n"]}]},{"cell_type":"markdown","source":["##nn.Flatten\n","nn.Flatten 계층을 초기화하여 각 28x28의 2D 이미지를 784 픽셀 값을 갖는 연속된 배열로 변환합니다. (dim=0의 미니배치 차원은 유지됩니다.)"],"metadata":{"id":"V1vzqycYu5Y5"}},{"cell_type":"code","source":["flatten = nn.Flatten()\n","flat_image = flatten(input_image)\n","print(flat_image.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ai4DZYSgu1BK","executionInfo":{"status":"ok","timestamp":1677213814137,"user_tz":-540,"elapsed":276,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"69e0774c-ee4f-4b87-8a4e-e05a710e5a48"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 784])\n"]}]},{"cell_type":"markdown","source":["##nn.Linear\n","선형 계층 은 저장된 가중치(weight)와 편향(bias)을 사용하여 입력에 선형 변환(linear transformation)을 적용하는 모듈입니다."],"metadata":{"id":"eI2rfsr4vDXw"}},{"cell_type":"code","source":["layer1 = nn.Linear(in_features=28*28, out_features=20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVOgDSZlu8na","executionInfo":{"status":"ok","timestamp":1677213858815,"user_tz":-540,"elapsed":258,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"a3c1e3cb-8757-490b-8158-d9fd252401c3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 20])\n"]}]},{"cell_type":"markdown","source":["##nn.ReLU\n","비선형 활성화(activation)는 모델의 입력과 출력 사이에 복잡한 관계(mapping)를 만듭니다. 비선형 활성화는 선형 변환 후에 적용되어 비선형성(nonlinearity) 을 도입하고, 신경망이 다양한 현상을 학습할 수 있도록 돕습니다.\n","\n","이 모델에서는 nn.ReLU 를 선형 계층들 사이에 사용하지만, 모델을 만들 때는 비선형성을 가진 다른 활성화를 도입할 수도 있습니다."],"metadata":{"id":"BX8-yhpkvOop"}},{"cell_type":"code","source":["print(f\"Before ReLU: {hidden1}\\n\\n\")\n","hidden1 = nn.ReLU()(hidden1)\n","print(f\"After ReLU: {hidden1}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sW0IchtOvHgF","executionInfo":{"status":"ok","timestamp":1677213896304,"user_tz":-540,"elapsed":249,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"732fef41-960a-4385-d779-5a0c8ad54e53"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Before ReLU: tensor([[ 0.1537, -0.2353,  0.5648,  0.1479,  0.3464, -0.3737,  0.4656,  0.1503,\n","          0.5467, -0.2997, -0.3249,  0.4170, -0.2618,  0.2654,  0.0928,  0.1899,\n","         -0.1695,  0.4426,  0.2139, -0.1111],\n","        [ 0.3701, -0.1211,  0.1228, -0.1350,  0.0931, -0.0507,  0.4185, -0.0819,\n","          0.2127, -0.0733, -0.4328,  0.2503, -0.1763,  0.1164, -0.2413,  0.2684,\n","         -0.0104,  0.7372,  0.1901, -0.1907],\n","        [ 0.1860, -0.2638,  0.2369,  0.2237,  0.1023, -0.5372,  0.1005, -0.0515,\n","          0.3994, -0.4148, -0.0834,  0.7503, -0.2072,  0.1769, -0.0412,  0.1235,\n","          0.2256,  0.5146,  0.6059, -0.4484]], grad_fn=<AddmmBackward0>)\n","\n","\n","After ReLU: tensor([[0.1537, 0.0000, 0.5648, 0.1479, 0.3464, 0.0000, 0.4656, 0.1503, 0.5467,\n","         0.0000, 0.0000, 0.4170, 0.0000, 0.2654, 0.0928, 0.1899, 0.0000, 0.4426,\n","         0.2139, 0.0000],\n","        [0.3701, 0.0000, 0.1228, 0.0000, 0.0931, 0.0000, 0.4185, 0.0000, 0.2127,\n","         0.0000, 0.0000, 0.2503, 0.0000, 0.1164, 0.0000, 0.2684, 0.0000, 0.7372,\n","         0.1901, 0.0000],\n","        [0.1860, 0.0000, 0.2369, 0.2237, 0.1023, 0.0000, 0.1005, 0.0000, 0.3994,\n","         0.0000, 0.0000, 0.7503, 0.0000, 0.1769, 0.0000, 0.1235, 0.2256, 0.5146,\n","         0.6059, 0.0000]], grad_fn=<ReluBackward0>)\n"]}]},{"cell_type":"markdown","source":["##nn.Sequential\n","nn.Sequential 은 순서를 갖는 모듈의 컨테이너입니다. 데이터는 정의된 것과 같은 순서로 모든 모듈들을 통해 전달됩니다. 순차 컨테이너(sequential container)를 사용하여 아래의 seq_modules 와 같은 신경망을 빠르게 만들 수 있습니다."],"metadata":{"id":"bKiHtbtBvUqQ"}},{"cell_type":"code","source":["seq_modules = nn.Sequential(\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20, 10)\n",")\n","input_image = torch.rand(3,28,28)\n","logits = seq_modules(input_image)"],"metadata":{"id":"M48VVq6gvQr7","executionInfo":{"status":"ok","timestamp":1677213919805,"user_tz":-540,"elapsed":6,"user":{"displayName":"이우성","userId":"00926902840550518962"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["##nn.Softmax\n","신경망의 마지막 선형 계층은 nn.Softmax 모듈에 전달될 ([-infty, infty] 범위의 원시 값(raw value)인) logits 를 반환합니다. logits는 모델의 각 분류(class)에 대한 예측 확률을 나타내도록 [0, 1] 범위로 비례하여 조정(scale)됩니다. dim 매개변수는 값의 합이 1이 되는 차원을 나타냅니다."],"metadata":{"id":"Y4n52mHNvfcY"}},{"cell_type":"code","source":["softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)"],"metadata":{"id":"gWOgfAJDvWbR","executionInfo":{"status":"ok","timestamp":1677213968934,"user_tz":-540,"elapsed":7,"user":{"displayName":"이우성","userId":"00926902840550518962"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["##모델 매개변수\n","신경망 내부의 많은 계층들은 매개변수화(parameterize) 됩니다. 즉, 학습 중에 최적화되는 가중치와 편향과 연관지어집니다. nn.Module 을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적(track)되며, 모델의 parameters() 및 named_parameters() 메소드로 모든 매개변수에 접근할 수 있게 됩니다.\n","\n","이 예제에서는 각 매개변수들을 순회하며(iterate), 매개변수의 크기와 값을 출력합니다."],"metadata":{"id":"AHTTxpP_vvWC"}},{"cell_type":"code","source":["print(f\"Model structure: {model}\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6yla1KvvifR","executionInfo":{"status":"ok","timestamp":1677214004605,"user_tz":-540,"elapsed":266,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"036603d6-85f8-4ffc-b18f-deccfff7d00e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model structure: NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","\n","\n"]}]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDtp8a45vrHK","executionInfo":{"status":"ok","timestamp":1677214104778,"user_tz":-540,"elapsed":4,"user":{"displayName":"이우성","userId":"00926902840550518962"}},"outputId":"bc767a2a-bbee-45c7-ee81-e21d84111198"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0173, -0.0126,  0.0197,  ..., -0.0186, -0.0295,  0.0332],\n","        [ 0.0063, -0.0350,  0.0261,  ..., -0.0079,  0.0239, -0.0207]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0185, -0.0229], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0162,  0.0362,  0.0344,  ...,  0.0434, -0.0352, -0.0018],\n","        [-0.0195,  0.0042, -0.0350,  ...,  0.0258, -0.0366,  0.0250]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0280, -0.0016], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0436,  0.0068, -0.0058,  ...,  0.0158,  0.0044, -0.0167],\n","        [ 0.0048,  0.0074,  0.0021,  ..., -0.0109, -0.0062, -0.0191]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0305,  0.0025], grad_fn=<SliceBackward0>) \n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qqX6YamTv1wG"},"execution_count":null,"outputs":[]}]}